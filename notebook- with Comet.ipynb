{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Starting a Comet Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet_ml in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (3.23.1)\n",
      "Requirement already satisfied: six in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (1.15.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (2.25.1)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (7.352.0)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (3.2.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (3.0.2)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (2.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (1.12.1)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (2.8.5)\n",
      "Requirement already satisfied: dulwich>=0.20.6 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (0.20.26)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (0.9.1)\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from comet_ml) (1.2.3)\n",
      "Requirement already satisfied: urllib3>=1.24.1 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from dulwich>=0.20.6->comet_ml) (1.26.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from dulwich>=0.20.6->comet_ml) (2020.12.5)\n",
      "Requirement already satisfied: configobj in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from everett[ini]>=1.0.1->comet_ml) (5.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (52.0.0.post20210125)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.17.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\cebisiles\\anaconda3\\lib\\site-packages (from requests>=2.18.4->comet_ml) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in 'C:\\\\Users\\\\CebisileS\\\\Downloads' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/cebisiles/unsupervised-learning/dd038f3cd39f4a0d84405e16ab2c68ee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"qPSB4ail2BLvJOkpLaqwE6FSe\",\n",
    "    project_name=\"unsupervised-learning\",\n",
    "    workspace=\"cebisiles\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:11.180482Z",
     "iopub.status.busy": "2022-02-03T15:31:11.179433Z",
     "iopub.status.idle": "2022-02-03T15:31:11.213009Z",
     "shell.execute_reply": "2022-02-03T15:31:11.212369Z",
     "shell.execute_reply.started": "2022-02-03T15:31:11.180348Z"
    },
    "id": "i2k0vdV4UGWk"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW6IgdQ-UNTk"
   },
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:11.978500Z",
     "iopub.status.busy": "2022-02-03T15:31:11.977547Z",
     "iopub.status.idle": "2022-02-03T15:31:12.936335Z",
     "shell.execute_reply": "2022-02-03T15:31:12.935403Z",
     "shell.execute_reply.started": "2022-02-03T15:31:11.978435Z"
    },
    "id": "-c636u02UGWw"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0bd7f3cc1080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msurprise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF54XhBzUYfk"
   },
   "source": [
    "The functions below they load the data and merge it based on the movie ID, simultanously, thus to save time other than indivisually doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TByTIIo8wIvL"
   },
   "outputs": [],
   "source": [
    "def load(s):\n",
    "    l=[]\n",
    "    for i in s:\n",
    "        l+=[pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/\"+i+\".csv\")]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:12.944593Z",
     "iopub.status.busy": "2022-02-03T15:31:12.944242Z",
     "iopub.status.idle": "2022-02-03T15:31:12.954713Z",
     "shell.execute_reply": "2022-02-03T15:31:12.953977Z",
     "shell.execute_reply.started": "2022-02-03T15:31:12.944550Z"
    },
    "id": "QLjx4rRlUGWz"
   },
   "outputs": [],
   "source": [
    "def merge_movie_id(s):\n",
    "    p=s[0]\n",
    "    d=s[1:]\n",
    "    for i in d:\n",
    "        p=p.merge(i,how='left',on='movieId')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:13.098135Z",
     "iopub.status.busy": "2022-02-03T15:31:13.097228Z",
     "iopub.status.idle": "2022-02-03T15:31:23.507609Z",
     "shell.execute_reply": "2022-02-03T15:31:23.506542Z",
     "shell.execute_reply.started": "2022-02-03T15:31:13.098078Z"
    },
    "id": "ZkVNXpkIUGW1"
   },
   "outputs": [],
   "source": [
    "train_df=merge_movie_id(load(['train','movies'])[:4])\n",
    "test_df=merge_movie_id(load(['test','movies'])[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IURCnDkAU_Cr"
   },
   "source": [
    "Thus from here we will consider the train df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:23.510068Z",
     "iopub.status.busy": "2022-02-03T15:31:23.509369Z",
     "iopub.status.idle": "2022-02-03T15:31:23.514548Z",
     "shell.execute_reply": "2022-02-03T15:31:23.513450Z",
     "shell.execute_reply.started": "2022-02-03T15:31:23.510030Z"
    },
    "id": "-eEauyPDUGW2"
   },
   "outputs": [],
   "source": [
    "df=train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPCW5aI4VHLf"
   },
   "source": [
    "Then we look at the five number summary of the Ratings as well as the standard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:23.516136Z",
     "iopub.status.busy": "2022-02-03T15:31:23.515906Z",
     "iopub.status.idle": "2022-02-03T15:31:23.962443Z",
     "shell.execute_reply": "2022-02-03T15:31:23.961588Z",
     "shell.execute_reply.started": "2022-02-03T15:31:23.516108Z"
    },
    "id": "p4g9QpGjUGW3"
   },
   "outputs": [],
   "source": [
    "df['rating'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB_J-4l1VY9C"
   },
   "source": [
    "From this we can see that the minimun rating for the data is 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKFptILJVzbW"
   },
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRmhurITWDca"
   },
   "source": [
    "Ratings Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KnB3TMUjee3k"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:24.075687Z",
     "iopub.status.busy": "2022-02-03T15:31:24.075462Z",
     "iopub.status.idle": "2022-02-03T15:31:25.092644Z",
     "shell.execute_reply": "2022-02-03T15:31:25.091692Z",
     "shell.execute_reply.started": "2022-02-03T15:31:24.075661Z"
    },
    "id": "pNyyRXOzUGXB"
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "data = df['rating'].value_counts().sort_index(ascending=False)\n",
    "trace = go.Bar(x = data.index,\n",
    "               text = ['{:.1f} %'.format(val) for val in (data.values / df.shape[0] * 100)],\n",
    "               textposition = 'auto',\n",
    "               textfont = dict(color = '#000000'),\n",
    "               y = data.values,\n",
    "               )\n",
    "# Create layout\n",
    "layout = dict(title = 'Distribution Of {} ratings'.format(df.shape[0]),\n",
    "              xaxis = dict(title = 'Rating'),\n",
    "              yaxis = dict(title = 'Count'))\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EykL7y1rUGXD"
   },
   "source": [
    "We can see that less than 13% of all ratings in the data have a rating of less or equal to 2, and low movies movie mean they are generally really bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:25.094524Z",
     "iopub.status.busy": "2022-02-03T15:31:25.094294Z",
     "iopub.status.idle": "2022-02-03T15:31:25.558697Z",
     "shell.execute_reply": "2022-02-03T15:31:25.557250Z",
     "shell.execute_reply.started": "2022-02-03T15:31:25.094497Z"
    },
    "id": "9_6D-bJ0UGXE"
   },
   "outputs": [],
   "source": [
    "# Number of ratings per book\n",
    "data = df.groupby('movieId')['rating'].count().clip(upper=50)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Ratings',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 50,\n",
    "                                  size = 2))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Number of Ratings Per Movie (Clipped at 50)',\n",
    "                   xaxis = dict(title = 'Number of Ratings Per Movie'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:25.561101Z",
     "iopub.status.busy": "2022-02-03T15:31:25.560430Z",
     "iopub.status.idle": "2022-02-03T15:31:25.940028Z",
     "shell.execute_reply": "2022-02-03T15:31:25.939200Z",
     "shell.execute_reply.started": "2022-02-03T15:31:25.561053Z"
    },
    "id": "14ljDBSrUGXF"
   },
   "outputs": [],
   "source": [
    "df.groupby('movieId')['rating'].count().reset_index().sort_values('rating', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyBJpv2XUGXG"
   },
   "source": [
    "Ratings Distribution By User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:25.941701Z",
     "iopub.status.busy": "2022-02-03T15:31:25.941403Z",
     "iopub.status.idle": "2022-02-03T15:31:26.498845Z",
     "shell.execute_reply": "2022-02-03T15:31:26.497930Z",
     "shell.execute_reply.started": "2022-02-03T15:31:25.941658Z"
    },
    "id": "aHwHEXa_UGXH"
   },
   "outputs": [],
   "source": [
    "# Number of ratings per user\n",
    "data = df.groupby('userId')['rating'].count().clip(upper=50)\n",
    "\n",
    "# Create trace\n",
    "trace = go.Histogram(x = data.values,\n",
    "                     name = 'Ratings',\n",
    "                     xbins = dict(start = 0,\n",
    "                                  end = 50,\n",
    "                                  size = 2))\n",
    "# Create layout\n",
    "layout = go.Layout(title = 'Distribution Of Number of Ratings Per User (Clipped at 50)',\n",
    "                   xaxis = dict(title = 'Ratings Per User'),\n",
    "                   yaxis = dict(title = 'Count'),\n",
    "                   bargap = 0.2)\n",
    "\n",
    "# Create plot\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:26.500411Z",
     "iopub.status.busy": "2022-02-03T15:31:26.500123Z",
     "iopub.status.idle": "2022-02-03T15:31:26.990828Z",
     "shell.execute_reply": "2022-02-03T15:31:26.989916Z",
     "shell.execute_reply.started": "2022-02-03T15:31:26.500377Z"
    },
    "id": "4I1_FqZJUGXI"
   },
   "outputs": [],
   "source": [
    "df.groupby('userId')['rating'].count().reset_index().sort_values('rating', ascending=False)[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:31:26.993188Z",
     "iopub.status.busy": "2022-02-03T15:31:26.992932Z",
     "iopub.status.idle": "2022-02-03T15:31:28.597986Z",
     "shell.execute_reply": "2022-02-03T15:31:28.597223Z",
     "shell.execute_reply.started": "2022-02-03T15:31:26.993140Z"
    },
    "id": "OKWL9uZYUGXJ"
   },
   "outputs": [],
   "source": [
    "min_movie_ratings = 2\n",
    "filter_movies = df['rating'].value_counts() > min_movie_ratings\n",
    "filter_movies = filter_movies[filter_movies].index.tolist()\n",
    "\n",
    "min_user_ratings = 50\n",
    "filter_users = df['userId'].value_counts() > min_user_ratings\n",
    "filter_users = filter_users[filter_users].index.tolist()\n",
    "\n",
    "df_new = df[(df['rating'].isin(filter_movies)) & (df['userId'].isin(filter_users))]\n",
    "print('The original data frame shape:\\t{}'.format(df.shape))\n",
    "print('The new data frame shape:\\t{}'.format(df_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YThRAH9MWhju"
   },
   "source": [
    "**Modelling with Surprise**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E64puOFTUGXK"
   },
   "source": [
    "To load a dataset from a pandas dataframe, we will use the load_from_df() method, we will also need a Reader object, and the rating_scale parameter must be specified. The dataframe must have three columns, corresponding to the user ids, the movie ids, and the ratings in this order. Each row thus corresponds to a given rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:41:45.106612Z",
     "iopub.status.busy": "2022-02-03T15:41:45.105836Z",
     "iopub.status.idle": "2022-02-03T15:41:45.613145Z",
     "shell.execute_reply": "2022-02-03T15:41:45.612146Z",
     "shell.execute_reply.started": "2022-02-03T15:41:45.106562Z"
    },
    "id": "TMHSipPpUGXK"
   },
   "outputs": [],
   "source": [
    "df = df_new.sample(50000)\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq42DwdaUGXL"
   },
   "source": [
    "With the Surprise library, we will benchmark the following algorithms\n",
    "\n",
    "# ****Basic algorithms****\n",
    "\n",
    "## **NormalPredictor**\n",
    "\n",
    "NormalPredictor algorithm predicts a random rating based on the distribution of the training set, which is assumed to be normal. This is one of the most basic algorithms that do not do much work.\n",
    "\n",
    "## **BaselineOnly**\n",
    "\n",
    "BasiclineOnly algorithm predicts the baseline estimate for given user and item.\n",
    "# **k-NN algorithms**\n",
    "## **KNNBasic**\n",
    "KNNBasic is a basic collaborative filtering algorithm.\n",
    "## **KNNWithMeans**\n",
    "KNNWithMeans is basic collaborative filtering algorithm, taking into account the mean ratings of each user.\n",
    "## **KNNWithZScore**\n",
    "KNNWithZScore is a basic collaborative filtering algorithm, taking into account the z-score normalization of each user.\n",
    "## **KNNBaseline**\n",
    "KNNBaseline is a basic collaborative filtering algorithm taking into account a baseline rating.\n",
    "\n",
    "# **Matrix Factorization-based algorithms**\n",
    "## **SVD**\n",
    "SVD algorithm is equivalent to Probabilistic Matrix Factorization (http://papers.nips.cc/paper/3208-probabilistic-matrix-factorization.pdf)\n",
    "\n",
    "## **SVDpp**\n",
    "The SVDpp algorithm is an extension of SVD that takes into account implicit ratings.\n",
    "\n",
    "## **NMF**\n",
    "NMF is a collaborative filtering algorithm based on Non-negative Matrix Factorization. It is very similar with SVD.\n",
    "\n",
    "## **Slope One**\n",
    "Slope One is a straightforward implementation of the SlopeOne algorithm. (https://arxiv.org/abs/cs/0702144)\n",
    "\n",
    "## **Co-clustering**\n",
    "Co-clustering is a collaborative filtering algorithm based on co-clustering (http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.113.6458&rep=rep1&type=pdf)\n",
    "\n",
    "KNNWithMeans(),, NormalPredictor(), KNNBaseline(), KNNBasic(),  KNNWithZScore(),\n",
    "\n",
    "\n",
    "**We use rmse as our accuracy metric for the predictions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:41:47.218586Z",
     "iopub.status.busy": "2022-02-03T15:41:47.218300Z",
     "iopub.status.idle": "2022-02-03T15:43:41.442274Z",
     "shell.execute_reply": "2022-02-03T15:43:41.441296Z",
     "shell.execute_reply.started": "2022-02-03T15:41:47.218556Z"
    },
    "id": "XKwaMrlaUGXN"
   },
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [SVD(), SVDpp(), KNNWithMeans(), SlopeOne(), NMF(), BaselineOnly(), CoClustering()]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:43:41.444865Z",
     "iopub.status.busy": "2022-02-03T15:43:41.444332Z",
     "iopub.status.idle": "2022-02-03T15:43:41.454756Z",
     "shell.execute_reply": "2022-02-03T15:43:41.453884Z",
     "shell.execute_reply.started": "2022-02-03T15:43:41.444812Z"
    },
    "id": "XzFsXJ4lUGXN"
   },
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:43:41.456133Z",
     "iopub.status.busy": "2022-02-03T15:43:41.455868Z",
     "iopub.status.idle": "2022-02-03T15:43:41.479514Z",
     "shell.execute_reply": "2022-02-03T15:43:41.478446Z",
     "shell.execute_reply.started": "2022-02-03T15:43:41.456102Z"
    },
    "id": "ax6HVlmXUGXO"
   },
   "outputs": [],
   "source": [
    "surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI1GwZOaUGXP"
   },
   "source": [
    "*SVDpp* algorithm gave us the best rmse, therefore, we will proceed further with *SVDpp* and use **Root Mean Square Error(RMSE)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:00.277740Z",
     "iopub.status.busy": "2022-02-03T15:44:00.277230Z",
     "iopub.status.idle": "2022-02-03T15:44:14.185469Z",
     "shell.execute_reply": "2022-02-03T15:44:14.184372Z",
     "shell.execute_reply.started": "2022-02-03T15:44:00.277698Z"
    },
    "id": "cqVaVXn6UGXQ"
   },
   "outputs": [],
   "source": [
    "print('Using ALS')\n",
    "bsl_options = {'method': 'als',\n",
    "               'n_epochs': 5,\n",
    "               'reg_u': 12,\n",
    "               'reg_i': 5\n",
    "               }\n",
    "algo = SVDpp()\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:14.187171Z",
     "iopub.status.busy": "2022-02-03T15:44:14.186904Z",
     "iopub.status.idle": "2022-02-03T15:44:19.299533Z",
     "shell.execute_reply": "2022-02-03T15:44:19.298462Z",
     "shell.execute_reply.started": "2022-02-03T15:44:14.187122Z"
    },
    "id": "XrD-0kJZUGXR"
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo = SVDpp()\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:28.095506Z",
     "iopub.status.busy": "2022-02-03T15:44:28.095174Z",
     "iopub.status.idle": "2022-02-03T15:44:28.101029Z",
     "shell.execute_reply": "2022-02-03T15:44:28.100385Z",
     "shell.execute_reply.started": "2022-02-03T15:44:28.095468Z"
    },
    "id": "UMwkBgVcUGXS"
   },
   "outputs": [],
   "source": [
    "trainset = algo.trainset\n",
    "print(algo.__class__.__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Vcfk3KwUGXS"
   },
   "source": [
    "### To inspect our predictions in details, we are going to build a pandas data frame with all the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:37.077604Z",
     "iopub.status.busy": "2022-02-03T15:44:37.077308Z",
     "iopub.status.idle": "2022-02-03T15:44:37.142276Z",
     "shell.execute_reply": "2022-02-03T15:44:37.141260Z",
     "shell.execute_reply.started": "2022-02-03T15:44:37.077574Z"
    },
    "id": "IvPMEYyBUGXT"
   },
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\" return the number of items rated by given user\n",
    "    args: \n",
    "      uid: the id of the user\n",
    "    returns: \n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError: # user was not part of the trainset\n",
    "        return 0\n",
    "    \n",
    "def get_Ui(iid):\n",
    "    \"\"\" return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "    \n",
    "df = pd.DataFrame(predictions, columns=['uid', 'iid', 'rui', 'est', 'details'])\n",
    "df['Iu'] = df.uid.apply(get_Iu)\n",
    "df['Ui'] = df.iid.apply(get_Ui)\n",
    "df['err'] = abs(df.est - df.rui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:38.895241Z",
     "iopub.status.busy": "2022-02-03T15:44:38.894913Z",
     "iopub.status.idle": "2022-02-03T15:44:38.909746Z",
     "shell.execute_reply": "2022-02-03T15:44:38.908896Z",
     "shell.execute_reply.started": "2022-02-03T15:44:38.895204Z"
    },
    "id": "S2T7sFWlUGXT"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:45.438402Z",
     "iopub.status.busy": "2022-02-03T15:44:45.438055Z",
     "iopub.status.idle": "2022-02-03T15:44:45.449422Z",
     "shell.execute_reply": "2022-02-03T15:44:45.448597Z",
     "shell.execute_reply.started": "2022-02-03T15:44:45.438352Z"
    },
    "id": "GLCMM_WrUGXU"
   },
   "outputs": [],
   "source": [
    "best_predictions = df.sort_values(by='err')[:10]\n",
    "worst_predictions = df.sort_values(by='err')[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:44:46.526096Z",
     "iopub.status.busy": "2022-02-03T15:44:46.525756Z",
     "iopub.status.idle": "2022-02-03T15:44:46.543828Z",
     "shell.execute_reply": "2022-02-03T15:44:46.542902Z",
     "shell.execute_reply.started": "2022-02-03T15:44:46.526060Z"
    },
    "id": "ef6asIiRUGXU"
   },
   "outputs": [],
   "source": [
    "best_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:45:16.253681Z",
     "iopub.status.busy": "2022-02-03T15:45:16.253326Z",
     "iopub.status.idle": "2022-02-03T15:45:16.272952Z",
     "shell.execute_reply": "2022-02-03T15:45:16.272140Z",
     "shell.execute_reply.started": "2022-02-03T15:45:16.253642Z"
    },
    "id": "5ieO5BQGUGXV"
   },
   "outputs": [],
   "source": [
    "worst_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8MtYLaZUGXW"
   },
   "source": [
    "### The worst predictions look pretty surprise. Let's look in more details of the last one movieID 79132, the movie was rated by 33 users, user \"136170\" rated 0.5, our SVDpp algorithm predicts 4,1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T15:52:21.515027Z",
     "iopub.status.busy": "2022-02-03T15:52:21.514688Z",
     "iopub.status.idle": "2022-02-03T15:52:47.951112Z",
     "shell.execute_reply": "2022-02-03T15:52:47.949980Z",
     "shell.execute_reply.started": "2022-02-03T15:52:21.514993Z"
    },
    "id": "13Ro_B6bUGXW"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(algo, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score['rmse'])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BL9qmSydg13"
   },
   "source": [
    "# Submission Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T16:59:50.72807Z",
     "iopub.status.busy": "2022-01-27T16:59:50.72783Z",
     "iopub.status.idle": "2022-01-27T17:06:28.378393Z",
     "shell.execute_reply": "2022-01-27T17:06:28.377384Z",
     "shell.execute_reply.started": "2022-01-27T16:59:50.728041Z"
    },
    "id": "8VteiwFRUGXb"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2e1f9419365f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0ml\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msvdpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'movieId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "l=[]\n",
    "for index, row in test_df.iterrows():\n",
    "    l+=[svdpp.predict(row['userId'], row['movieId']).est]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T17:18:48.25148Z",
     "iopub.status.busy": "2022-01-27T17:18:48.251166Z",
     "iopub.status.idle": "2022-01-27T17:18:59.580706Z",
     "shell.execute_reply": "2022-01-27T17:18:59.579732Z",
     "shell.execute_reply.started": "2022-01-27T17:18:48.251446Z"
    },
    "id": "CtPnxAupUGXe"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/edsa-movie-recommendation-wilderness/sample_submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-30db1ae5914f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/kaggle/input/edsa-movie-recommendation-wilderness/sample_submission.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/edsa-movie-recommendation-wilderness/sample_submission.csv'"
     ]
    }
   ],
   "source": [
    "sub=pd.read_csv(\"/kaggle/input/edsa-movie-recommendation-wilderness/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T17:18:59.582611Z",
     "iopub.status.busy": "2022-01-27T17:18:59.582343Z",
     "iopub.status.idle": "2022-01-27T17:19:01.220908Z",
     "shell.execute_reply": "2022-01-27T17:19:01.220054Z",
     "shell.execute_reply.started": "2022-01-27T17:18:59.58258Z"
    },
    "id": "lbyObGTgUGXf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f9485d481c39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rating'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub['rating']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-27T17:19:03.70495Z",
     "iopub.status.busy": "2022-01-27T17:19:03.704728Z",
     "iopub.status.idle": "2022-01-27T17:19:22.966058Z",
     "shell.execute_reply": "2022-01-27T17:19:22.965416Z",
     "shell.execute_reply.started": "2022-01-27T17:19:03.704926Z"
    },
    "id": "0w7RPvAlUGXh"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-496408217232>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submission.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sub' is not defined"
     ]
    }
   ],
   "source": [
    "sub.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/cebisiles/unsupervised-learning/e8522e7e31274f5aaea71b9bae69d407\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
